{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4deeb43-3268-4a23-b282-50b33860a18e",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5c8d3f-612f-471d-8645-455ed7c18a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "\n",
    "setup.init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf86428-6ffb-4fc6-9b9a-9535c2c4fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from blog.models import BlogPost \n",
    "from blog import services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca7fb28-1dce-41d4-a305-18b392e4a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs = BlogPost.objects.filter(can_delete=True)\n",
    "# qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae7ea19-2420-4c77-a60d-0761161d8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index sqlalchemy llama-index-vector-stores-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb2be8e-f174-4a03-8eed-1b90c8a6023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index llama-index-llms-gemini llama-index-embeddings-gemini google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e96f699-54bb-4049-aa10-69374ccc12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-llms-google-genai llama-index llama_index.embeddings.google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf5f1a7-8f8e-45cc-8083-2a51ac7bcced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "import google.generativeai as genai\n",
    "from llama_index.core import Settings\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359d8320-d92b-421b-8168-bed8f78ed8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_MODEL = config(\"EMBEDDING_MODEL\", default=\"gemini-embedding-exp-03-07\")\n",
    "EMBEDDING_LENGTH = config(\"EMBEDDING_LENGTH\", default=3072, cast=int)\n",
    "GEMINI_API_KEY = config(\"GEMINI_API_KEY\", cast=str)\n",
    "LLM_MODEL = config(\"LLM_MODEL\", default=\"gemini-2.0-flash\")\n",
    "\n",
    "EMBEDDING_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a11b043f-b638-4264-a71c-bdfd266518f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenAI(\n",
    "    model=LLM_MODEL,\n",
    "    api_key=GEMINI_API_KEY, \n",
    ")\n",
    "embed_model = GoogleGenAIEmbedding(\n",
    "    model_name=EMBEDDING_MODEL,\n",
    "    api_key = GEMINI_API_KEY,\n",
    "    dimensions=3072,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe7db76-2d2c-4fca-a480-15fae7a4c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class MyGoogleGenAIEmbedding(GoogleGenAIEmbedding):\n",
    "    \n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        \"\"\"Get query embedding.\"\"\"\n",
    "        print(f\"My Query: {query}\")\n",
    "        return super()._get_query_embedding(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Get text embedding.\"\"\"\n",
    "        print(f\"Text: {text}\")\n",
    "        return super()._get_text_embedding([text])\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Get text embeddings.\"\"\"\n",
    "        print(f\"Texts: {texts}\")\n",
    "        return super()._get_text_embeddings(texts)\n",
    "\n",
    "embed_model = MyGoogleGenAIEmbedding(\n",
    "    model_name = EMBEDDING_MODEL,\n",
    "    api_key = GEMINI_API_KEY,\n",
    "    dimensions=3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34c4285-5013-4dce-b4f7-502c28e67f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "embed_model = GoogleGenAIEmbedding(\n",
    "    model_name=EMBEDDING_MODEL,\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    dimensions=3072,\n",
    ")\n",
    "sample_text = \"Test text\"\n",
    "embedding = embed_model.get_text_embedding(sample_text)\n",
    "print(len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccdcd85a-ccdb-4d02-87e5-c42c8a6c6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b24aeacc-55a3-46de-a1de-8a50c19e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_name = \"vector_db\"\n",
    "vector_db_table_name = \"blogpost\" # -> data_blogpost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936198e5-6b4f-44e0-8fee-b60b946a4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = config(\"DATABASE_URL_POOL\")\n",
    "if DATABASE_URL.startswith(\"postgres://\"):\n",
    "    DATABASE_URL = DATABASE_URL.replace(\"postgres://\", \"postgresql://\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158878e3-0e30-423a-9821-ec4b7d0109c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(DATABASE_URL, isolation_level=\"AUTOCOMMIT\")\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT 1 FROM pg_database WHERE datname = :db_name\"), {\"db_name\": vector_db_name})\n",
    "    db_exists = result.scalar() == 1\n",
    "    if not db_exists:\n",
    "        connection.execute(text('CREATE EXTENSION IF NOT EXISTS vector'))\n",
    "        connection.execute(text(f\"CREATE DATABASE {vector_db_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "360e2233-7406-4cdc-ad31-1e78447c07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "\n",
    "url = make_url(DATABASE_URL)\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=vector_db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port or 5432,\n",
    "    user=url.username,\n",
    "    table_name=vector_db_table_name,\n",
    "    embed_dim=EMBEDDING_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "708cdd55-2ca9-4c37-9b41-75ff1814a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ec80b9-9758-4739-ab6f-8134e5b1b442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='I am sorry, I cannot answer your query as it is empty.\\n', source_nodes=[NodeWithScore(node=TextNode(id_='5e2471bc-e539-4d24-b1dd-828eed7883e4', embedding=None, metadata={'pk': 272, 'title': 'Blog Post 3'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='272', node_type='4', metadata={'pk': 272, 'title': 'Blog Post 3'}, hash='a24f0a8a2afac5e73456f07599c23e73ad3ffea30d4b47994521c7316a22bb2b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The day is bright', mimetype='text/plain', start_char_idx=0, end_char_idx=17, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.642418876198892), NodeWithScore(node=TextNode(id_='067d3b72-0973-4a12-908f-10a5c4a4b076', embedding=None, metadata={'pk': 273, 'title': 'Blog Post 4'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='273', node_type='4', metadata={'pk': 273, 'title': 'Blog Post 4'}, hash='35ac21819d7257e9eb86440a6767e4f3b38451aed3379b7e2038a2ad5963c085')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The man is dark and woman is light', mimetype='text/plain', start_char_idx=0, end_char_idx=34, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6282442961030404)], metadata={'5e2471bc-e539-4d24-b1dd-828eed7883e4': {'pk': 272, 'title': 'Blog Post 3'}, '067d3b72-0973-4a12-908f-10a5c4a4b076': {'pk': 273, 'title': 'Blog Post 4'}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query(\"My query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a61916-bd56-4cf3-8906-ce24f213337b",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e657b108-80b2-437f-b347-ab755cc01bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "docs = []\n",
    "qs = BlogPost.objects.filter(can_delete=True)\n",
    "for obj in qs:\n",
    "    docs.append(\n",
    "        Document(\n",
    "            text=f\"{obj.get_embedding_text_raw()}\",\n",
    "            doc_id=str(obj.id),\n",
    "            embedding=obj.embedding.tolist(),\n",
    "            metadata = {\n",
    "                \"pk\": obj.pk,\n",
    "                \"title\": obj.title\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb384130-bae8-4570-9682-b9d09a64b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    index.delete_ref_doc(f\"{doc.id_}\", delete_from_docstore=True)\n",
    "    index.insert(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330fbf26-9e83-47d0-8d00-42b9da74c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"The day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8f7c506-8be4-406f-8d78-8b1a1a242c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The day is bright\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ce8bfeb-17c8-49ea-928b-dff11a000193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pk 272\n",
      "title Blog Post 3\n",
      "pk 273\n",
      "title Blog Post 4\n"
     ]
    }
   ],
   "source": [
    "for item in response.metadata:\n",
    "    for subk, v in response.metadata[item].items():\n",
    "        print(subk, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15418c-099e-491c-9f94-9d48b818be4d",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2b0077a-22dd-44d2-ae57-6840b6320c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = url.port or 5432\n",
    "db_url = f\"postgresql://{url.username}:{url.password}@{url.host}:{port}/{vector_db_name}\"\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "engine =  create_engine(db_url)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    # Define the SQL query to select only the id and embedding columns\n",
    "    query = text(f\"SELECT * FROM data_{vector_db_table_name}\")\n",
    "    query = text(f\"SELECT metadata_, embedding FROM data_{vector_db_table_name}\")\n",
    "    \n",
    "    # Execute the query\n",
    "    result = connection.execute(query)\n",
    "    \n",
    "    # Fetch all rows\n",
    "    rows = result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9b627bb-33c5-4062-934a-f25739aef6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_metrics(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitude1 = np.linalg.norm(v1)\n",
    "    magnitude2 = np.linalg.norm(v2)\n",
    "    cosine_similarity = dot_product / (magnitude1 * magnitude2)\n",
    "    cosine_distance = 1 - cosine_similarity\n",
    "    return int(cosine_similarity* 100), int(cosine_distance * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1e4e2c9-b57f-4765-89c1-89f772d7b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 0)\n",
      "(100, 0)\n",
      "(100, 0)\n",
      "(100, 0)\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    metadata_, embedding = row[0], row[1]\n",
    "    # print(metadata_)\n",
    "    # print(embedding)\n",
    "\n",
    "    blog_post_pk = metadata_.get(\"pk\")\n",
    "    obj = BlogPost.objects.get(pk=blog_post_pk)\n",
    "    # print(obj.embedding, embedding)\n",
    "    embedding_array = np.array(embedding.strip('[]').split(','), dtype=float)\n",
    "    obj_embedding_array = np.array(obj.embedding, dtype=float)\n",
    "    print(calculate_cosine_metrics(embedding_array.shape, obj_embedding_array.shape))\n",
    "    # print(obj.embedding, embedding)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb75da-b215-42bb-9230-ea4eb63f7885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d43374a-4369-4cd4-9ecb-6af08a901359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
